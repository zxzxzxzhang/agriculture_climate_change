{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-10-31T11:50:56.415760Z",
     "start_time": "2024-10-31T11:50:50.979351Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_excel('data_2011-2015.xlsx')\n",
    "df = df.dropna(subset=['摘要(译)(English)'])\n",
    "df = df[df['摘要(译)(English)'] != '-']\n",
    "df1 = df.dropna(subset=['摘要(译)(English)'])\n",
    "df1"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:50:56.432063Z",
     "start_time": "2024-10-31T11:50:56.419773Z"
    }
   },
   "source": [
    "def truncate_text(text, max_length=510, redundancy=20):\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "    \n",
    "    end_idx_cn = text.rfind('。', 0, max_length)\n",
    "    end_idx_en = text.rfind('.', 0, max_length)\n",
    "    \n",
    "    end_idx = max(end_idx_cn, end_idx_en)\n",
    "    \n",
    "    if end_idx == -1:\n",
    "        start_idx = max_length - redundancy if max_length > redundancy else 0\n",
    "        end_idx = max_length + redundancy if len(text) > max_length + redundancy else len(text)\n",
    "        return text[start_idx:end_idx]\n",
    "    else:\n",
    "        return text[:end_idx + 1]\n",
    "\n",
    "df1['摘要(译)(English)'] = df1['摘要(译)(English)'].apply(lambda x: truncate_text(x, max_length=512))"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:50:56.447369Z",
     "start_time": "2024-10-31T11:50:56.434724Z"
    }
   },
   "source": "df1 = df1[['摘要(译)(English)']]",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-31T11:51:20.605479Z",
     "start_time": "2024-10-31T11:50:56.449557Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(r'distilbert-base-nli-mean-tokens')\n",
    "\n",
    "model = DistilBertModel.from_pretrained(r'distilbert-base-nli-mean-tokens')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return embedding\n",
    "\n",
    "text = df1['摘要(译)(English)'].values.tolist()\n",
    "embeddings = get_text_embedding(text)\n",
    "embeddings = embeddings.detach().cpu().numpy()\n",
    "print(embeddings.shape)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:52:07.068612Z",
     "start_time": "2024-10-31T11:51:20.610477Z"
    }
   },
   "source": [
    "import umap\n",
    "umap_model = umap.UMAP(n_components=3, random_state=2022)\n",
    "\n",
    "umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "umap_embeddings.shape"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:52:13.844298Z",
     "start_time": "2024-10-31T11:52:07.068612Z"
    }
   },
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SSE = []\n",
    "for k in range(1, 8):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(umap_embeddings)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 8), SSE, 'o-')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.title(\"Elbow Method For Optimal k\")\n",
    "plt.show()"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-31T11:52:14.942437Z",
     "start_time": "2024-10-31T11:52:13.844298Z"
    }
   },
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster = KMeans(n_clusters=3, random_state=2024).fit(umap_embeddings)\n",
    "labels = cluster.labels_\n",
    "\n",
    "df['cluster'] = labels"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:52:14.974114Z",
     "start_time": "2024-10-31T11:52:14.942437Z"
    }
   },
   "source": [
    "df1['cluster'] = cluster.labels_\n",
    "df1['cluster'].value_counts()\n",
    "df2 = df1"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:52:21.800752Z",
     "start_time": "2024-10-31T11:52:21.659763Z"
    }
   },
   "cell_type": "code",
   "source": "df1.to_excel('s3.xlsx', index = False)",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:33.286975Z",
     "start_time": "2024-10-28T04:35:30.413980Z"
    }
   },
   "source": [
    "import jieba\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "def filter_text(text):    \n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    pattern = re.compile(r'[^a-zA-Z\\s]')\n",
    "    text = pattern.sub(' ', text)\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return ' '.join(filtered_words)\n",
    "df2['摘要(译)(English)'] = df2['摘要(译)(English)'].astype(str)\n",
    "df2['摘要(译)(English)'] = [filter_text(item) for item in df2['摘要(译)(English)']]"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:33.300168Z",
     "start_time": "2024-10-28T04:35:33.289050Z"
    }
   },
   "source": [
    "df3 = df2\n",
    "\n",
    "df3['cluster'] = cluster.labels_\n",
    "df3.head()\n",
    "\n",
    "cluster0 = df3[df3['cluster']==0]\n",
    "cluster0.head()"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:35.707658Z",
     "start_time": "2024-10-28T04:35:33.300679Z"
    }
   },
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "def get_top_n_words(text, top_n=10):\n",
    "    model = KeyBERT(r'all-mpnet-base-v2')\n",
    "    keywords = model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=top_n)\n",
    "    return keywords\n",
    "\n",
    "merged_text = ' '.join(cluster0['摘要(译)(English)'].tolist())\n",
    "\n",
    "keywords = get_top_n_words(merged_text, top_n=10)\n",
    "keywords"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:35.723078Z",
     "start_time": "2024-10-28T04:35:35.709987Z"
    }
   },
   "source": [
    "cluster0 = df3[df3['cluster']==0]\n",
    "cluster1 = df3[df3['cluster']==1]\n",
    "cluster2 = df3[df3['cluster']==2]\n",
    "c0 = ' '.join(cluster0['摘要(译)(English)'].tolist())\n",
    "c1 = ' '.join(cluster1['摘要(译)(English)'].tolist())\n",
    "c2 = ' '.join(cluster2['摘要(译)(English)'].tolist())"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:38.985654Z",
     "start_time": "2024-10-28T04:35:35.724195Z"
    }
   },
   "source": [
    "df4 = []\n",
    "\n",
    "common_words = get_top_n_words(c0, 10)\n",
    "df4.append(common_words)\n",
    "common_words = get_top_n_words(c1, 10)\n",
    "df4.append(common_words)\n",
    "\n",
    "common_words = get_top_n_words(c2, 10)\n",
    "df4.append(common_words)\n",
    "\n",
    "df5 = pd.DataFrame(df4)\n",
    "df5 = df5.T\n",
    "df5.columns = ['cluster0','cluster1','cluster2']\n",
    "df5"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:39.026382Z",
     "start_time": "2024-10-28T04:35:38.986164Z"
    }
   },
   "source": [
    "df5.to_excel('result_2011-2015.xlsx',index=False)"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
