{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:49:40.476866Z",
     "start_time": "2024-10-31T11:49:28.141864Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_excel('data_2001-2010.xlsx')\n",
    "df = df[df['摘要(译)(English)'] != '-']\n",
    "df = df.dropna(subset=['摘要(译)(English)'])\n",
    "df1 = df\n",
    "df1"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:49:40.492265Z",
     "start_time": "2024-10-31T11:49:40.480026Z"
    }
   },
   "source": [
    "def truncate_text(text, max_length=510, redundancy=20):\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "    \n",
    "    end_idx_cn = text.rfind('。', 0, max_length)\n",
    "    end_idx_en = text.rfind('.', 0, max_length)\n",
    "    \n",
    "    end_idx = max(end_idx_cn, end_idx_en)\n",
    "    \n",
    "    if end_idx == -1:\n",
    "        start_idx = max_length - redundancy if max_length > redundancy else 0\n",
    "        end_idx = max_length + redundancy if len(text) > max_length + redundancy else len(text)\n",
    "        return text[start_idx:end_idx]\n",
    "    else:\n",
    "        return text[:end_idx + 1]\n",
    "\n",
    "df1['摘要(译)(English)'] = df1['摘要(译)(English)'].apply(lambda x: truncate_text(x, max_length=512))"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:49:40.507603Z",
     "start_time": "2024-10-31T11:49:40.495366Z"
    }
   },
   "source": "df1 = df1[['摘要(译)(English)']]",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-31T11:50:07.329460Z",
     "start_time": "2024-10-31T11:49:40.511255Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 加载预训练模型和分词器\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(r'distilbert-base-nli-mean-tokens')\n",
    "# 加载微调后的模型\n",
    "model = DistilBertModel.from_pretrained(r'distilbert-base-nli-mean-tokens')\n",
    "model = model.to(device)\n",
    "\n",
    "# 将文本转换为嵌入向量\n",
    "def get_text_embedding(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return embedding\n",
    "\n",
    "text = df1['摘要(译)(English)'].values.tolist()\n",
    "embeddings = get_text_embedding(text)\n",
    "embeddings = embeddings.detach().cpu().numpy()\n",
    "print(embeddings.shape)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:50:32.261618Z",
     "start_time": "2024-10-31T11:50:07.331851Z"
    }
   },
   "source": [
    "import umap\n",
    "umap_model = umap.UMAP(n_components=3, random_state=2022)\n",
    "umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "umap_embeddings.shape"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:50:34.845446Z",
     "start_time": "2024-10-31T11:50:32.263618Z"
    }
   },
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SSE = []\n",
    "for k in range(1, 8):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(umap_embeddings)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 8), SSE, 'o-')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.title(\"Elbow Method For Optimal k\")\n",
    "plt.show()"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-31T11:50:34.892162Z",
     "start_time": "2024-10-31T11:50:34.848529Z"
    }
   },
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster = KMeans(n_clusters=2, random_state=2024).fit(umap_embeddings)\n",
    "labels = cluster.labels_\n",
    "\n",
    "df['cluster'] = labels"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:50:34.907276Z",
     "start_time": "2024-10-31T11:50:34.894224Z"
    }
   },
   "source": [
    "df1['cluster'] = cluster.labels_\n",
    "df1.head()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:50:34.922404Z",
     "start_time": "2024-10-31T11:50:34.909279Z"
    }
   },
   "source": [
    "df1['cluster'].value_counts()"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:51:44.957110Z",
     "start_time": "2024-10-31T11:51:44.647700Z"
    }
   },
   "cell_type": "code",
   "source": "df1.to_excel('s2.xlsx', index = False)",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:07.795350Z",
     "start_time": "2024-10-28T04:35:07.790479Z"
    }
   },
   "source": [
    "df2 = df1"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:10.753026Z",
     "start_time": "2024-10-28T04:35:08.043936Z"
    }
   },
   "source": [
    "import jieba\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "def filter_text(text):    \n",
    "    # 去除括号及其内部内容\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    # 去除所有符号和数字\n",
    "    pattern = re.compile(r'[^a-zA-Z\\s]')\n",
    "    text = pattern.sub(' ', text)\n",
    "    # 分词\n",
    "    words = text.split()\n",
    "    # 过滤停用词、标点符号以及人称代词、感叹词、连接词和介词\n",
    "    filtered_words = [word for word in words if word not in stopwords.words('english')]\n",
    "    # 拼接过滤后的单词并返回\n",
    "    return ' '.join(filtered_words)\n",
    "df2['摘要(译)(English)'] = df2['摘要(译)(English)'].astype(str)\n",
    "df2['摘要(译)(English)'] = [filter_text(item) for item in df2['摘要(译)(English)']]"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:10.765425Z",
     "start_time": "2024-10-28T04:35:10.755220Z"
    }
   },
   "source": [
    "df3 = df2\n",
    "df3['cluster'] = cluster.labels_\n",
    "cluster0 = df3[df3['cluster']==0]"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:12.595330Z",
     "start_time": "2024-10-28T04:35:10.765425Z"
    }
   },
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "def get_top_n_words(text, top_n=10):\n",
    "    model = KeyBERT(r'all-mpnet-base-v2')\n",
    "    keywords = model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=top_n)\n",
    "    return keywords\n",
    "\n",
    "merged_text = ' '.join(cluster0['摘要(译)(English)'].tolist())\n",
    "\n",
    "keywords = get_top_n_words(merged_text, top_n=10)\n",
    "keywords"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:12.608832Z",
     "start_time": "2024-10-28T04:35:12.596463Z"
    }
   },
   "source": [
    "cluster0 = df3[df3['cluster']==0]\n",
    "cluster1 = df3[df3['cluster']==1]\n",
    "c0 = ' '.join(cluster0['摘要(译)(English)'].tolist())\n",
    "c1 = ' '.join(cluster1['摘要(译)(English)'].tolist())"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:14.698426Z",
     "start_time": "2024-10-28T04:35:12.608832Z"
    }
   },
   "source": [
    "df4 = []\n",
    "\n",
    "common_words = get_top_n_words(c0, 10)\n",
    "df4.append(common_words)\n",
    "common_words = get_top_n_words(c1, 10)\n",
    "df4.append(common_words)\n",
    "\n",
    "df5 = pd.DataFrame(df4)\n",
    "df5 = df5.T\n",
    "df5.columns = ['cluster0','cluster1']\n",
    "df5"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T04:35:59.324380Z",
     "start_time": "2024-10-28T04:35:59.287293Z"
    }
   },
   "source": [
    "df5.to_excel('result_2001-2010.xlsx',index=False)"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
